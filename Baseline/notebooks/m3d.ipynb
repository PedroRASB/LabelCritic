{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_sam_vit_3d...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016acb4b9a7c45bf8dfb03d64b93055f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch, warnings, os\n",
    "import nibabel as nib\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TRANSFORMERS_CACHE'] = './HFCache'\n",
    "os.environ['HF_HOME'] = './HFCache'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "device = torch.device('cuda') # 'cpu', 'cuda'\n",
    "dtype = torch.bfloat16 # or bfloat16, float16, float32\n",
    "\n",
    "# model_name_or_path = '/mnt/ccvl15/qwu59/checkpoints/m3d/M3D-LaMed-Phi-3-4B'\n",
    "model_name_or_path = '/mnt/sdh/qwu59/ckpts/m3d/M3D-LaMed-Phi-3-4B'\n",
    "proj_out_num = 256\n",
    "\n",
    "# Prepare your 3D medical image:\n",
    "# 1. The image shape needs to be processed as 1*32*256*256, consider resize and other methods.\n",
    "# 2. The image needs to be normalized to 0-1, consider Min-Max Normalization.\n",
    "# 3. The image format needs to be converted to .npy \n",
    "# 4. Although we did not train on 2D images, in theory, the 2D image can be interpolated to the shape of 1*32*256*256 for input.\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    torch_dtype=dtype,\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    model_max_length=512,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(question, ct_pro, seg_enable=False, branch='ct'):\n",
    "    image_tokens = \"<im_patch>\" * proj_out_num\n",
    "    input_txt = image_tokens + question\n",
    "    input_id = tokenizer(\n",
    "        input_txt,\n",
    "        return_tensors=\"pt\"\n",
    "    )['input_ids'].to(device=device)\n",
    "    attention_mask = tokenizer(\n",
    "        input_txt,\n",
    "        return_tensors=\"pt\", \n",
    "        padding=True\n",
    "    )['attention_mask'].to(device=device)\n",
    "\n",
    "    if branch == 'ct':\n",
    "        image_pt = ct_pro.transformed[\"image\"].unsqueeze(0).to(device=device).type(dtype)\n",
    "    elif branch == 'ctmin':\n",
    "        image_pt = ct_pro.ctmin_transformed[\"image\"].unsqueeze(0).to(device=device).type(dtype)\n",
    "    # generation, seg_logit = model.generate(\n",
    "    outputs = model.generate(\n",
    "        image_pt,\n",
    "        input_id,\n",
    "        attention_mask=attention_mask,\n",
    "        seg_enable=seg_enable,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    if seg_enable:\n",
    "        generation, seg_logit = outputs\n",
    "        seg_mask = ((torch.sigmoid(seg_logit) > 0.5) * 1.0).squeeze(0)\n",
    "        return tokenizer.batch_decode(generation, skip_special_tokens=True)[0], seg_mask\n",
    "    else:\n",
    "        generation = outputs\n",
    "        return tokenizer.batch_decode(generation, skip_special_tokens=True)[0]\n",
    "\n",
    "import random\n",
    "def batch_inference(question, ct_pro, seg_enable=False, branch='ct'):\n",
    "    image_tokens = \"<im_patch>\" * proj_out_num\n",
    "    # input_txt = image_tokens + questions\n",
    "    questions = [pre + question for pre in ['Please answer the quesion', 'Question', '']]\n",
    "    input_txts = [image_tokens + random.choice(questions) for _ in range(3)]\n",
    "    input_ids = tokenizer(\n",
    "        input_txts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        padding_side=\"left\",\n",
    "    )['input_ids'].to(device=device)\n",
    "    print(input_ids.shape)\n",
    "    attention_masks = tokenizer(\n",
    "        input_txts,\n",
    "        return_tensors=\"pt\", \n",
    "        padding=True,\n",
    "        padding_side=\"left\"\n",
    "    )['attention_mask'].to(device=device)\n",
    "\n",
    "    if branch == 'ct':\n",
    "        image_pt = ct_pro.transformed[\"image\"].unsqueeze(0).to(device=device).type(dtype)\n",
    "    elif branch == 'ctmin':\n",
    "        image_pt = ct_pro.ctmin_transformed[\"image\"].unsqueeze(0).to(device=device).type(dtype)\n",
    "    image_pts = torch.cat([image_pt for _ in range(3)], dim=0)\n",
    "    # print(image_pt.shape, image_pts.shape)\n",
    "    # generation, seg_logit = model.generate(\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            image_pts,\n",
    "            input_ids,\n",
    "            attention_mask=attention_masks,\n",
    "            seg_enable=seg_enable,\n",
    "            max_new_tokens=64,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=1.0\n",
    "        )\n",
    "    if seg_enable:\n",
    "        generation, seg_logit = outputs\n",
    "        seg_mask = ((torch.sigmoid(seg_logit) > 0.5) * 1.0).squeeze(0)\n",
    "        return tokenizer.batch_decode(generation, skip_special_tokens=True), seg_mask\n",
    "    else:\n",
    "        generation = outputs\n",
    "        return tokenizer.batch_decode(generation, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test for single prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_1_q(organ):\n",
    "    return \"Does the bone ct image contain the {}? Answer yes or no.\".format(organ)\n",
    "\n",
    "def step_2_q(organ):\n",
    "    return (\n",
    "        \"The lowest intensity white area within the body in this bone ct image\"\n",
    "        \"is the {} mask annotation. \".format(organ) +\n",
    "        \"Is it correct? Only answer yes or no.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load CT image from: /mnt/sdh/qwu59/data/s0015/ct.nii.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4.606508255004883\n",
      "Question 1: Does the bone ct image contain the kidneys? Answer yes or no.\n",
      "Answer 1: Yes\n",
      "********************************************************************************\n",
      "Question 2: The lowest intensity white area within the body in this bone ct imageis the kidneys mask annotation. Is it correct? Only answer yes or no.\n",
      "Answer 2: Yes\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import opti_tf as ctf\n",
    "# import custom_tf as ctf\n",
    "from importlib import reload\n",
    "reload(ctf)\n",
    "\n",
    "import time\n",
    "case_path = \"/mnt/sdh/qwu59/data/s0015\"\n",
    "# test this step run time\n",
    "start = time.time()\n",
    "ct_pro = ctf.CTImageProcessor(case_path, ct_name=\"ct\", mask_name=\"kidneys\")\n",
    "print(\"Time:\", time.time() - start)\n",
    "organ = \"kidneys\"\n",
    "question1 = step_1_q(organ)\n",
    "question2 = step_2_q(organ)\n",
    "text1 = inference(question1, ct_pro, branch='ct') # branch='ct' or 'ctmin'\n",
    "text2 = inference(question2, ct_pro, branch='ctmin')\n",
    "print(\"Question 1:\", question1)\n",
    "print(\"Answer 1:\", text1)\n",
    "print(\"*\" * 80)\n",
    "print(\"Question 2:\", question2)\n",
    "print(\"Answer 2:\", text2)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# generated_texts = batch_inference(question2, ct_pro, branch='ctmin')\n",
    "# print(generated_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Organize the data json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def append_dict_to_csv(dict_data, csv_path):\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    with open(csv_path, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=dict_data.keys())\n",
    "        if file.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(dict_data)\n",
    "        \n",
    "def step_1_q(organ):\n",
    "    return \"Does the bone ct image contain the {}? Answer yes or no.\".format(organ)\n",
    "\n",
    "def step_2_q(organ):\n",
    "    return (\n",
    "        \"The lowest intensity white area within the body in this bone ct image\"\n",
    "        \"is the {} mask annotation. \".format(organ) +\n",
    "        \"What do you think of this? Is it correct? Only answer yes or no.\"\n",
    "    )\n",
    "    \n",
    "result_path = \"results/m3d/\"\n",
    "\n",
    "task1_path = \"/mnt/sdh/pedro/AbdomenAtlasBeta/\"\n",
    "task1 = \"bad_labels_AbdomenAtlasBeta.json\"\n",
    "\n",
    "task2_path = \"/mnt/sdc/pedro/ErrorDetection/cropped_nnunet_results_250Epch\"\n",
    "task2_path_ = \"/mnt/sdc/pedro/ErrorDetection/cropped_nnunet_results_250Epch_liver\"\n",
    "task2 = \"bad_labels_nnUnet.json\"\n",
    "\n",
    "task3_path = \"/mnt/sdh/pedro/AbdomenAtlasBeta/\"\n",
    "task3 = \"good_labels_AbdomenAtlasBeta.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organ: kidneys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 856.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organ: pancreas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1232.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organ: gall_bladder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 890.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organ: postcava\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 1464.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organ: stomach\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 852.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organ: spleen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1907.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organ: aorta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00000031', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00004290', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00004236', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00001045', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'no', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00001483', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Incorrect', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00004834', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Incorrect', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00000003', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n",
      "{'sample': 'BDMAP_00001230', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00000233', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Incorrect', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00004457', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Incorrect', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00003935', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Incorrect', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [05:40<00:00, 28.37s/it]\n",
      " 88%|████████▊ | 7/8 [05:40<00:48, 48.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00003976', 'organ': 'aorta', 'part': 'errors_beta_full', 'result step 1': 'present', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n",
      "Organ: liver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00001808', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00001992', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00001537', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Incorrect', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00001032', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00002316', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00001399', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00001095', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00001044', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00002727', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Incorrect', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00003467', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Incorrect', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:24<00:00,  7.70s/it]\n",
      "100%|██████████| 8/8 [07:05<00:00, 53.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': 'BDMAP_00003023', 'organ': 'liver', 'part': 'errors_beta_full', 'result step 1': 'no', 'label step 1': 'present', 'result step 2': 'Correct', 'label step 2': 'Incorrect'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the json file for task 1\n",
    "with open(task1) as f:\n",
    "    task1_data = json.load(f)\n",
    "\n",
    "for i, organ in enumerate(tqdm(task1_data)):\n",
    "    print(\"Organ:\", organ)\n",
    "    question1 = step_1_q(organ)\n",
    "    question2 = step_2_q(organ)\n",
    "    for j, case in enumerate(tqdm(task1_data[organ])):\n",
    "        # check whether the case exists in the final csv\n",
    "        check_table = os.path.join(result_path, \"final\", \"errors_beta_full.csv\")\n",
    "        skip_sign = False\n",
    "        if os.path.exists(check_table):\n",
    "            with open(check_table, mode='r') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                for row in reader:\n",
    "                    if row[\"sample\"] == case and row[\"organ\"] == organ:\n",
    "                        skip_sign = True\n",
    "                        break\n",
    "        if skip_sign:\n",
    "            continue\n",
    "        case_path = os.path.join(task1_path, case)\n",
    "        # print(\"Case:\", case, case_path)\n",
    "        ct_pro = ctf.CTImageProcessor(case_path, ct_name=\"ct\", mask_name=organ)\n",
    "        text1 = inference(question1, ct_pro, branch='ct')\n",
    "        text2 = inference(question2, ct_pro, branch='ctmin')\n",
    "        task1_raw = {\n",
    "            \"sample\": case,\n",
    "            \"organ\": organ,\n",
    "            \"part\": \"errors_beta_full\",\n",
    "            \"question1\": question1,\n",
    "            \"answer1\": text1,\n",
    "            \"question2\": question2,\n",
    "            \"answer2\": text2\n",
    "        }\n",
    "        task1_single = {\n",
    "            \"sample\": case,\n",
    "            \"organ\": organ,\n",
    "            \"part\": \"errors_beta_full\",\n",
    "            \"result step 1\": \"present\" if \"yes\" in text1.lower() else \"no\",\n",
    "            \"label step 1\": \"present\" if ct_pro.mask_present else \"no\",\n",
    "            \"result step 2\": \"Correct\" if \"yes\" in text2.lower() else \"Incorrect\",\n",
    "            \"label step 2\": \"Incorrect\",\n",
    "        }\n",
    "        print(task1_single)\n",
    "        append_dict_to_csv(task1_raw, os.path.join(result_path, \"raw\", \"errors_beta_full.csv\"))\n",
    "        append_dict_to_csv(task1_single, os.path.join(result_path, \"final\", \"errors_beta_full.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file for task 2\n",
    "with open(task2) as f:\n",
    "    task2_data = json.load(f)\n",
    "\n",
    "for i, organ in enumerate(tqdm(task2_data)):\n",
    "    print(\"Organ:\", organ)\n",
    "    question1 = step_1_q(organ)\n",
    "    question2 = step_2_q(organ)\n",
    "    for j, case in enumerate(tqdm(task2_data[organ])):\n",
    "        case_path = os.path.join(task2_path, case)\n",
    "        # print(\"Case:\", case, case_path)\n",
    "        ct_pro = ctf.CTImageProcessor(case_path, ct_name=\"ct\", mask_name=organ)\n",
    "        text1 = inference(question1, ct_pro, branch='ct')\n",
    "        text2 = inference(question2, ct_pro, branch='ctmin')\n",
    "        task2_raw = {\n",
    "            \"sample\": case,\n",
    "            \"organ\": organ,\n",
    "            \"part\": \"errors_nnUnet_full\",\n",
    "            \"question1\": question1,\n",
    "            \"answer1\": text1,\n",
    "            \"question2\": question2,\n",
    "            \"answer2\": text2\n",
    "        }\n",
    "        task2_single = {\n",
    "            \"sample\": case,\n",
    "            \"organ\": organ,\n",
    "            \"part\": \"errors_nnUnet_full\",\n",
    "            \"result step 1\": \"present\" if \"yes\" in text1.lower() else \"no\",\n",
    "            \"label step 1\": \"present\" if ct_pro.mask_present else \"no\",\n",
    "            \"result step 2\": \"Correct\" if \"yes\" in text2.lower() else \"Incorrect\",\n",
    "            \"label step 2\": \"Incorrect\",\n",
    "        }\n",
    "        append_dict_to_csv(task2_raw, os.path.join(result_path, \"raw\", \"errors_nnUnet_full.csv\"))\n",
    "        append_dict_to_csv(task2_single, os.path.join(result_path, \"final\", \"errors_nnUnet_full.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file for task 1\n",
    "with open(task3) as f:\n",
    "    task3_data = json.load(f)\n",
    "\n",
    "for i, organ in enumerate(tqdm(task1_data)):\n",
    "    print(\"Organ:\", organ)\n",
    "    question1 = step_1_q(organ)\n",
    "    question2 = step_2_q(organ)\n",
    "    for j, case in enumerate(tqdm(task3_data[organ])):\n",
    "        case_path = os.path.join(task3_path, case)\n",
    "        # print(\"Case:\", case, case_path)\n",
    "        ct_pro = ctf.CTImageProcessor(case_path, ct_name=\"ct\", mask_name=organ)\n",
    "        text1 = inference(question1, ct_pro, branch='ct')\n",
    "        text2 = inference(question2, ct_pro, branch='ctmin')\n",
    "        task3_raw = {\n",
    "            \"sample\": case,\n",
    "            \"organ\": organ,\n",
    "            \"part\": \"good_labels_beta_full\",\n",
    "            \"question1\": question1,\n",
    "            \"answer1\": text1,\n",
    "            \"question2\": question2,\n",
    "            \"answer2\": text2\n",
    "        }\n",
    "        task3_single = {\n",
    "            \"sample\": case,\n",
    "            \"organ\": organ,\n",
    "            \"part\": \"errors_beta_full\",\n",
    "            \"result step 1\": \"present\" if \"yes\" in text1.lower() else \"no\",\n",
    "            \"label step 1\": \"present\" if ct_pro.mask_present else \"no\",\n",
    "            \"result step 2\": \"Correct\" if \"yes\" in text2.lower() else \"Incorrect\",\n",
    "            \"label step 2\": \"Correct\",\n",
    "        }\n",
    "        append_dict_to_csv(task3_raw, os.path.join(result_path, \"raw\", \"good_labels_beta_full.csv\"))\n",
    "        append_dict_to_csv(task3_single, os.path.join(result_path, \"final\", \"good_labels_beta_full.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
